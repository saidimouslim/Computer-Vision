{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2pu3UDGGuFGt",
        "outputId": "e2db5cd2-eee4-4302-8188-ee809894c6ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 2s (2,685 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123630 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (11.0.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d trainingdatapro/ocr-receipts-text-detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tmHIqGB8wE45",
        "outputId": "8b8d4cc6-eb9e-4500-e88a-1500b03b99b5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/trainingdatapro/ocr-receipts-text-detection\n",
            "License(s): Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)\n",
            "Downloading ocr-receipts-text-detection.zip to /content\n",
            " 78% 41.0M/52.6M [00:00<00:00, 70.7MB/s]\n",
            "100% 52.6M/52.6M [00:00<00:00, 71.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/ocr-receipts-text-detection.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "K0SjCksHwQ38",
        "outputId": "41380bae-5035-48f5-c3a0-9a264771df1b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/ocr-receipts-text-detection.zip\n",
            "  inflating: annotations.xml         \n",
            "  inflating: boxes/0.png             \n",
            "  inflating: boxes/1.png             \n",
            "  inflating: boxes/10.png            \n",
            "  inflating: boxes/11.png            \n",
            "  inflating: boxes/12.png            \n",
            "  inflating: boxes/13.png            \n",
            "  inflating: boxes/14.png            \n",
            "  inflating: boxes/15.png            \n",
            "  inflating: boxes/16.png            \n",
            "  inflating: boxes/17.png            \n",
            "  inflating: boxes/18.png            \n",
            "  inflating: boxes/19.png            \n",
            "  inflating: boxes/2.png             \n",
            "  inflating: boxes/3.png             \n",
            "  inflating: boxes/4.png             \n",
            "  inflating: boxes/5.png             \n",
            "  inflating: boxes/6.png             \n",
            "  inflating: boxes/7.png             \n",
            "  inflating: boxes/8.png             \n",
            "  inflating: boxes/9.png             \n",
            "  inflating: images/0.jpg            \n",
            "  inflating: images/1.jpg            \n",
            "  inflating: images/10.jpg           \n",
            "  inflating: images/11.jpg           \n",
            "  inflating: images/12.jpg           \n",
            "  inflating: images/13.jpg           \n",
            "  inflating: images/14.jpg           \n",
            "  inflating: images/15.jpg           \n",
            "  inflating: images/16.jpg           \n",
            "  inflating: images/17.jpg           \n",
            "  inflating: images/18.jpg           \n",
            "  inflating: images/19.jpg           \n",
            "  inflating: images/2.jpg            \n",
            "  inflating: images/3.jpg            \n",
            "  inflating: images/4.jpg            \n",
            "  inflating: images/5.jpg            \n",
            "  inflating: images/6.JPG            \n",
            "  inflating: images/7.jpg            \n",
            "  inflating: images/8.jpg            \n",
            "  inflating: images/9.jpg            \n",
            "  inflating: receipts.csv            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fwZ_m9POhK-e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytesseract\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ReceiptOCRExtractor:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the Receipt OCR Extractor\n",
        "        \"\"\"\n",
        "        self.model = None\n",
        "        self.scaler = None\n",
        "\n",
        "    def preprocess_image(self, image_path):\n",
        "        \"\"\"\n",
        "        Preprocess the receipt image for better OCR accuracy\n",
        "\n",
        "        Args:\n",
        "            image_path (str): Path to the input image\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: Preprocessed image\n",
        "        \"\"\"\n",
        "        # Read the image\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Convert to grayscale\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply thresholding to preprocess the image\n",
        "        gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
        "\n",
        "        # Apply denoising\n",
        "        gray = cv2.medianBlur(gray, 3)\n",
        "\n",
        "        return gray\n",
        "\n",
        "    def extract_text(self, image):\n",
        "        \"\"\"\n",
        "        Extract text from preprocessed image using Tesseract\n",
        "\n",
        "        Args:\n",
        "            image (numpy.ndarray): Preprocessed image\n",
        "\n",
        "        Returns:\n",
        "            str: Extracted text\n",
        "        \"\"\"\n",
        "        # Extract text from image\n",
        "        text = pytesseract.image_to_string(image)\n",
        "        return text\n",
        "\n",
        "    def parse_receipt_text(self, text):\n",
        "        \"\"\"\n",
        "        Parse extracted text to extract meaningful information\n",
        "\n",
        "        Args:\n",
        "            text (str): Extracted text from receipt\n",
        "\n",
        "        Returns:\n",
        "            dict: Extracted receipt information\n",
        "        \"\"\"\n",
        "        # Initialize default values\n",
        "        receipt_info = {\n",
        "            'total': None,\n",
        "            'date': None,\n",
        "            'store_name': None,\n",
        "            'items': [],\n",
        "            'tax': None\n",
        "        }\n",
        "\n",
        "        # Regular expressions for extraction\n",
        "        total_pattern = r'\\b(?:total|grand total)[:]*\\s*\\$?(\\d+\\.\\d{2})\\b'\n",
        "        date_pattern = r'\\b(\\d{1,2}/\\d{1,2}/\\d{2,4})\\b'\n",
        "\n",
        "        # Extract total\n",
        "        total_match = re.search(total_pattern, text, re.IGNORECASE)\n",
        "        if total_match:\n",
        "            receipt_info['total'] = float(total_match.group(1))\n",
        "\n",
        "        # Extract date\n",
        "        date_match = re.search(date_pattern, text)\n",
        "        if date_match:\n",
        "            receipt_info['date'] = date_match.group(1)\n",
        "\n",
        "        # Extract store name (first line of text)\n",
        "        lines = text.split('\\n')\n",
        "        if lines:\n",
        "            receipt_info['store_name'] = lines[0].strip()\n",
        "\n",
        "        # Extract items (simple parsing)\n",
        "        item_pattern = r'^(.+)\\s+\\$?(\\d+\\.\\d{2})$'\n",
        "        for line in lines[1:]:\n",
        "            item_match = re.match(item_pattern, line.strip())\n",
        "            if item_match:\n",
        "                receipt_info['items'].append({\n",
        "                    'name': item_match.group(1).strip(),\n",
        "                    'price': float(item_match.group(2))\n",
        "                })\n",
        "\n",
        "        # Extract tax\n",
        "        tax_pattern = r'\\b(?:tax)[:]*\\s*\\$?(\\d+\\.\\d{2})\\b'\n",
        "        tax_match = re.search(tax_pattern, text, re.IGNORECASE)\n",
        "        if tax_match:\n",
        "            receipt_info['tax'] = float(tax_match.group(1))\n",
        "\n",
        "        return receipt_info\n",
        "\n",
        "    def train_classification_model(self, receipt_dataset):\n",
        "        \"\"\"\n",
        "        Train a classification model to improve receipt type detection\n",
        "\n",
        "        Args:\n",
        "            receipt_dataset (list): List of receipt features\n",
        "\n",
        "        Returns:\n",
        "            tuple: Trained model and scaler\n",
        "        \"\"\"\n",
        "        # Prepare features and labels\n",
        "        X = [receipt['features'] for receipt in receipt_dataset]\n",
        "        y = [receipt['label'] for receipt in receipt_dataset]\n",
        "\n",
        "        # Split the data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Scale features\n",
        "        self.scaler = StandardScaler()\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "        # Train Random Forest Classifier\n",
        "        self.model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "        self.model.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # Evaluate the model\n",
        "        y_pred = self.model.predict(X_test_scaled)\n",
        "        print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "        print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "        return self.model, self.scaler\n",
        "\n",
        "    def process_receipt(self, image_path):\n",
        "        \"\"\"\n",
        "        Process a single receipt image\n",
        "\n",
        "        Args:\n",
        "            image_path (str): Path to receipt image\n",
        "\n",
        "        Returns:\n",
        "            dict: Extracted receipt information\n",
        "        \"\"\"\n",
        "        # Preprocess image\n",
        "        preprocessed_image = self.preprocess_image(image_path)\n",
        "\n",
        "        # Extract text\n",
        "        extracted_text = self.extract_text(preprocessed_image)\n",
        "\n",
        "        # Parse receipt text\n",
        "        receipt_info = self.parse_receipt_text(extracted_text)\n",
        "\n",
        "        return receipt_info\n",
        "\n",
        "    def process_receipt_batch(self, image_folder, output_csv='receipts_output.csv'):\n",
        "        \"\"\"\n",
        "        Process multiple receipt images in a batch\n",
        "\n",
        "        Args:\n",
        "            image_folder (str): Folder containing receipt images\n",
        "            output_csv (str): Path to output CSV file\n",
        "\n",
        "        Returns:\n",
        "            pandas.DataFrame: DataFrame with extracted receipt information\n",
        "        \"\"\"\n",
        "        receipts_data = []\n",
        "\n",
        "        # Process each image in the folder\n",
        "        for filename in os.listdir(image_folder):\n",
        "            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff')):\n",
        "                image_path = os.path.join(image_folder, filename)\n",
        "                try:\n",
        "                    receipt_info = self.process_receipt(image_path)\n",
        "                    receipt_info['filename'] = filename\n",
        "                    receipts_data.append(receipt_info)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        df = pd.DataFrame(receipts_data)\n",
        "\n",
        "        # Save to CSV\n",
        "        df.to_csv(output_csv, index=False)\n",
        "        print(f\"Receipts data saved to {output_csv}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def save_model(self, model_path='receipt_ocr_model.joblib'):\n",
        "        \"\"\"\n",
        "        Save trained model and scaler\n",
        "\n",
        "        Args:\n",
        "            model_path (str): Path to save the model\n",
        "        \"\"\"\n",
        "        if self.model and self.scaler:\n",
        "            joblib.dump({\n",
        "                'model': self.model,\n",
        "                'scaler': self.scaler\n",
        "            }, model_path)\n",
        "            print(f\"Model and scaler saved to {model_path}\")\n",
        "        else:\n",
        "            print(\"No model to save. Train the model first.\")"
      ],
      "metadata": {
        "id": "K8PieY7vhaad"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "def main():\n",
        "    # Initialize the extractor\n",
        "    extractor = ReceiptOCRExtractor()\n",
        "\n",
        "    # Process a batch of receipts\n",
        "    results_df = extractor.process_receipt_batch('/content/images')\n",
        "\n",
        "    # Optional: Train a classification model if you have a labeled dataset\n",
        "    # receipt_dataset = [\n",
        "    #     {'features': [...], 'label': 'grocery'},\n",
        "    #     {'features': [...], 'label': 'restaurant'}\n",
        "    # ]\n",
        "    # model, scaler = extractor.train_classification_model(receipt_dataset)\n",
        "    # extractor.save_model()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrZwG4YyhadX",
        "outputId": "ae58ac12-1d7b-463e-c7e0-6d33f92f6e07"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Receipts data saved to receipts_output.csv\n"
          ]
        }
      ]
    }
  ]
}